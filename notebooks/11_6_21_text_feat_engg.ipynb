{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0dbaa56355543e5e694c750fbaa3f1bda27eea84b84693d9eb9d2f61641d8d05a",
   "display_name": "Python 3.9.5 64-bit ('news_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# motive: vectorize the preprocessed data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             heading  \\\n",
       "0  murdering abuse domestic man partner swansea f...   \n",
       "1  second covid-19 prevent deadly to india wave f...   \n",
       "2       blow say firm blaze northampton owners cruel   \n",
       "\n",
       "                                             content  \n",
       "0  bottles without family ferocious assault never...  \n",
       "1  health immunity second march narendra covid-19...  \n",
       "2  fire swept urged felt who devastating tackle h...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>heading</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>murdering abuse domestic man partner swansea f...</td>\n      <td>bottles without family ferocious assault never...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>second covid-19 prevent deadly to india wave f...</td>\n      <td>health immunity second march narendra covid-19...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>blow say firm blaze northampton owners cruel</td>\n      <td>fire swept urged felt who devastating tackle h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/preprocessed/bbc_toi_yahoo_preprocessed_0_8.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    input='content',\n",
    "    encoding='utf-8',\n",
    "    decode_error='strict',\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    analyzer='word',\n",
    "    stop_words=None,\n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "    ngram_range=(1, 1),\n",
    "    max_df=1.,\n",
    "    min_df=0.01,\n",
    "    max_features=None,\n",
    "    vocabulary=None,\n",
    "    binary=False,\n",
    "    dtype=np.float64,\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_vectors_tfidf = vectorizer.fit_transform(data.loc[:, \"content\"])\n",
    "heading_vectors_tfidf = vectorizer.fit_transform(data.loc[:, \"heading\"])\n",
    "df_vectors_tfidf = pd.DataFrame.sparse.from_spmatrix(\n",
    "    data=content_vectors_tfidf,\n",
    "    columns=[f\"content_{i}\" for i in range(content_vectors_tfidf.shape[1])]\n",
    ")\n",
    "df_vectors_tfidf_h = pd.DataFrame.sparse.from_spmatrix(\n",
    "    data=heading_vectors_tfidf,\n",
    "    columns=[f\"heading_{i}\" for i in range(heading_vectors_tfidf.shape[1])]\n",
    ")\n",
    "\n",
    "df_vectors_tfidf = pd.concat(objs=[df_vectors_tfidf_h, df_vectors_tfidf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   heading_0  heading_1  heading_2  heading_3  heading_4  heading_5  \\\n",
       "0   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "1   0.689996        0.0        0.0        0.0        0.0        0.0   \n",
       "2   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "3   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "4   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   heading_6  heading_7  heading_8  heading_9  ...  content_1337  \\\n",
       "0        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "3        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "\n",
       "   content_1338  content_1339  content_1340  content_1341  content_1342  \\\n",
       "0           0.0      0.000000           0.0      0.078823      0.101704   \n",
       "1           0.0      0.000000           0.0      0.000000      0.000000   \n",
       "2           0.0      0.000000           0.0      0.000000      0.099908   \n",
       "3           0.0      0.220102           0.0      0.000000      0.000000   \n",
       "4           0.0      0.000000           0.0      0.087057      0.000000   \n",
       "\n",
       "   content_1343  content_1344  content_1345  content_1346  \n",
       "0           0.0           0.0      0.155937           0.0  \n",
       "1           0.0           0.0      0.000000           0.0  \n",
       "2           0.0           0.0      0.000000           0.0  \n",
       "3           0.0           0.0      0.000000           0.0  \n",
       "4           0.0           0.0      0.172226           0.0  \n",
       "\n",
       "[5 rows x 1405 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>heading_0</th>\n      <th>heading_1</th>\n      <th>heading_2</th>\n      <th>heading_3</th>\n      <th>heading_4</th>\n      <th>heading_5</th>\n      <th>heading_6</th>\n      <th>heading_7</th>\n      <th>heading_8</th>\n      <th>heading_9</th>\n      <th>...</th>\n      <th>content_1337</th>\n      <th>content_1338</th>\n      <th>content_1339</th>\n      <th>content_1340</th>\n      <th>content_1341</th>\n      <th>content_1342</th>\n      <th>content_1343</th>\n      <th>content_1344</th>\n      <th>content_1345</th>\n      <th>content_1346</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.078823</td>\n      <td>0.101704</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.155937</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.689996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.099908</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.220102</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.087057</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.172226</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1405 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_vectors_tfidf.to_csv(\"../data/vectorized/vectorized_tfidf.csv\")\n",
    "df_vectors_tfidf.head()"
   ]
  },
  {
   "source": [
    "## spacy vectors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "nlp = en_core_web_lg.load(disable = ['ner', 'tagger', 'parser'])\n",
    "nlp(\"bruh this is nlp\").vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(document, nlp):\n",
    "    vector_output = []\n",
    "    for word in document.split(\" \"):\n",
    "        if word in nlp.vocab:\n",
    "            nlp_word = nlp(word)\n",
    "            vector_output.append(nlp(nlp_word[-1].lemma_).vector)\n",
    "        else:\n",
    "            nlp.vocab.set_vector(word, np.random.randn(300))\n",
    "            vector_output.append(nlp(word).vector)\n",
    "    \n",
    "    return np.mean(vector_output, axis=0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7900/7900 [00:03<00:00, 2371.29it/s]\n",
      "100%|██████████| 7900/7900 [00:21<00:00, 359.16it/s]\n"
     ]
    }
   ],
   "source": [
    "heading_vectors_spacy = data.loc[:, \"heading\"].progress_apply(\n",
    "    lambda article: vectorize(document=article, nlp=nlp)\n",
    ")\n",
    "content_vectors_spacy = data.loc[:, \"content\"].progress_apply(\n",
    "    lambda article: vectorize(document=article, nlp=nlp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors_spacy = pd.DataFrame(\n",
    "    data=np.concatenate(content_vectors_spacy.values.reshape(-1)).reshape(-1, 300),\n",
    "    columns=[f\"content_{i}\" for i in range(300)]\n",
    ")\n",
    "df_vectors_spacy_h = pd.DataFrame(\n",
    "    data=np.concatenate(heading_vectors_spacy.values.reshape(-1)).reshape(-1, 300),\n",
    "    columns=[f\"heading_{i}\" for i in range(300)]\n",
    ")\n",
    "df_vectors_spacy = pd.concat(objs=[df_vectors_spacy_h, df_vectors_spacy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(7900, 600)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   heading_0  heading_1  heading_2  heading_3  heading_4  heading_5  \\\n",
       "0  -0.395403  -0.141887  -0.492862   0.348586  -0.228022  -0.553083   \n",
       "1  -0.002046  -0.373139   0.246757   0.089691   0.274580  -0.107132   \n",
       "2   0.764498   0.476539  -0.689963  -0.005024   0.334456  -0.208725   \n",
       "3  -0.331006  -0.404886   0.281067   0.035025  -0.548491   0.123478   \n",
       "4   0.390195  -0.330829  -0.051395  -0.382031  -0.041006  -0.046889   \n",
       "\n",
       "   heading_6  heading_7  heading_8  heading_9  ...  content_290  content_291  \\\n",
       "0  -0.253479   0.587059   0.080005   0.046023  ...    -0.130801     0.223726   \n",
       "1  -0.437309   0.017011  -0.074606   0.394424  ...    -0.112900     0.025790   \n",
       "2  -0.116030  -0.259741   0.176904   0.119457  ...    -0.010727    -0.093692   \n",
       "3  -0.088566  -0.284744  -0.504703  -0.204405  ...    -0.245446     0.030049   \n",
       "4  -0.100032   0.363283  -0.519215   0.699297  ...     0.014218    -0.093208   \n",
       "\n",
       "   content_292  content_293  content_294  content_295  content_296  \\\n",
       "0     0.014547     0.162810    -0.044603    -0.040171    -0.056706   \n",
       "1     0.079606     0.156572    -0.065178     0.029136    -0.011666   \n",
       "2    -0.034266     0.141945    -0.177817     0.093211     0.091080   \n",
       "3     0.103651    -0.242751    -0.070178     0.042648     0.052237   \n",
       "4     0.039565    -0.051338     0.144061    -0.120748    -0.121784   \n",
       "\n",
       "   content_297  content_298  content_299  \n",
       "0    -0.039914     0.066073    -0.090223  \n",
       "1    -0.071578    -0.103075    -0.034777  \n",
       "2     0.134218    -0.079569    -0.120034  \n",
       "3    -0.206619    -0.008419     0.120597  \n",
       "4    -0.102259    -0.094109     0.129041  \n",
       "\n",
       "[5 rows x 600 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>heading_0</th>\n      <th>heading_1</th>\n      <th>heading_2</th>\n      <th>heading_3</th>\n      <th>heading_4</th>\n      <th>heading_5</th>\n      <th>heading_6</th>\n      <th>heading_7</th>\n      <th>heading_8</th>\n      <th>heading_9</th>\n      <th>...</th>\n      <th>content_290</th>\n      <th>content_291</th>\n      <th>content_292</th>\n      <th>content_293</th>\n      <th>content_294</th>\n      <th>content_295</th>\n      <th>content_296</th>\n      <th>content_297</th>\n      <th>content_298</th>\n      <th>content_299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.395403</td>\n      <td>-0.141887</td>\n      <td>-0.492862</td>\n      <td>0.348586</td>\n      <td>-0.228022</td>\n      <td>-0.553083</td>\n      <td>-0.253479</td>\n      <td>0.587059</td>\n      <td>0.080005</td>\n      <td>0.046023</td>\n      <td>...</td>\n      <td>-0.130801</td>\n      <td>0.223726</td>\n      <td>0.014547</td>\n      <td>0.162810</td>\n      <td>-0.044603</td>\n      <td>-0.040171</td>\n      <td>-0.056706</td>\n      <td>-0.039914</td>\n      <td>0.066073</td>\n      <td>-0.090223</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.002046</td>\n      <td>-0.373139</td>\n      <td>0.246757</td>\n      <td>0.089691</td>\n      <td>0.274580</td>\n      <td>-0.107132</td>\n      <td>-0.437309</td>\n      <td>0.017011</td>\n      <td>-0.074606</td>\n      <td>0.394424</td>\n      <td>...</td>\n      <td>-0.112900</td>\n      <td>0.025790</td>\n      <td>0.079606</td>\n      <td>0.156572</td>\n      <td>-0.065178</td>\n      <td>0.029136</td>\n      <td>-0.011666</td>\n      <td>-0.071578</td>\n      <td>-0.103075</td>\n      <td>-0.034777</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.764498</td>\n      <td>0.476539</td>\n      <td>-0.689963</td>\n      <td>-0.005024</td>\n      <td>0.334456</td>\n      <td>-0.208725</td>\n      <td>-0.116030</td>\n      <td>-0.259741</td>\n      <td>0.176904</td>\n      <td>0.119457</td>\n      <td>...</td>\n      <td>-0.010727</td>\n      <td>-0.093692</td>\n      <td>-0.034266</td>\n      <td>0.141945</td>\n      <td>-0.177817</td>\n      <td>0.093211</td>\n      <td>0.091080</td>\n      <td>0.134218</td>\n      <td>-0.079569</td>\n      <td>-0.120034</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.331006</td>\n      <td>-0.404886</td>\n      <td>0.281067</td>\n      <td>0.035025</td>\n      <td>-0.548491</td>\n      <td>0.123478</td>\n      <td>-0.088566</td>\n      <td>-0.284744</td>\n      <td>-0.504703</td>\n      <td>-0.204405</td>\n      <td>...</td>\n      <td>-0.245446</td>\n      <td>0.030049</td>\n      <td>0.103651</td>\n      <td>-0.242751</td>\n      <td>-0.070178</td>\n      <td>0.042648</td>\n      <td>0.052237</td>\n      <td>-0.206619</td>\n      <td>-0.008419</td>\n      <td>0.120597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.390195</td>\n      <td>-0.330829</td>\n      <td>-0.051395</td>\n      <td>-0.382031</td>\n      <td>-0.041006</td>\n      <td>-0.046889</td>\n      <td>-0.100032</td>\n      <td>0.363283</td>\n      <td>-0.519215</td>\n      <td>0.699297</td>\n      <td>...</td>\n      <td>0.014218</td>\n      <td>-0.093208</td>\n      <td>0.039565</td>\n      <td>-0.051338</td>\n      <td>0.144061</td>\n      <td>-0.120748</td>\n      <td>-0.121784</td>\n      <td>-0.102259</td>\n      <td>-0.094109</td>\n      <td>0.129041</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 600 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "df_vectors_spacy.to_csv(\"../data/vectorized/vectorized_spacy.csv\")\n",
    "print(df_vectors_spacy.shape)\n",
    "df_vectors_spacy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.11009459]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "cosine_similarity(df_vectors_spacy.loc[13].values.reshape(1, -1), df_vectors_spacy.loc[34].values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.3291562]])"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "cosine_similarity(np.array(df_vectors_tfidf.loc[13].values).reshape(1, -1),\n",
    "np.array(df_vectors_tfidf.loc[1].values).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}