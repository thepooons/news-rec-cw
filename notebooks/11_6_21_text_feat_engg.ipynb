{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0dbaa56355543e5e694c750fbaa3f1bda27eea84b84693d9eb9d2f61641d8d05a",
   "display_name": "Python 3.9.5 64-bit ('news_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# motive: vectorize the preprocessed data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             heading  \\\n",
       "0  murdering abuse domestic man partner swansea f...   \n",
       "1  second covid-19 prevent deadly to india wave f...   \n",
       "2       blow say firm blaze northampton owners cruel   \n",
       "\n",
       "                                             content  \n",
       "0  bottles without family ferocious assault never...  \n",
       "1  health immunity second march narendra covid-19...  \n",
       "2  fire swept urged felt who devastating tackle h...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>heading</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>murdering abuse domestic man partner swansea f...</td>\n      <td>bottles without family ferocious assault never...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>second covid-19 prevent deadly to india wave f...</td>\n      <td>health immunity second march narendra covid-19...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>blow say firm blaze northampton owners cruel</td>\n      <td>fire swept urged felt who devastating tackle h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/preprocessed/bbc_toi_yahoo_preprocessed_0_8.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    input='content',\n",
    "    encoding='utf-8',\n",
    "    decode_error='strict',\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    analyzer='word',\n",
    "    stop_words=None,\n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "    ngram_range=(1, 1),\n",
    "    max_df=1.,\n",
    "    min_df=0.01,\n",
    "    max_features=None,\n",
    "    vocabulary=None,\n",
    "    binary=False,\n",
    "    dtype=np.float64,\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_vectors_tfidf = vectorizer.fit_transform(data.loc[:, \"content\"])\n",
    "heading_vectors_tfidf = vectorizer.fit_transform(data.loc[:, \"heading\"])\n",
    "df_vectors_tfidf = pd.DataFrame.sparse.from_spmatrix(\n",
    "    data=content_vectors_tfidf,\n",
    "    columns=[f\"content_{i}\" for i in range(content_vectors_tfidf.shape[1])]\n",
    ")\n",
    "df_vectors_tfidf_h = pd.DataFrame.sparse.from_spmatrix(\n",
    "    data=heading_vectors_tfidf,\n",
    "    columns=[f\"heading_{i}\" for i in range(heading_vectors_tfidf.shape[1])]\n",
    ")\n",
    "\n",
    "df_vectors_tfidf = pd.concat(objs=[df_vectors_tfidf_h, df_vectors_tfidf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   heading_0  heading_1  heading_2  heading_3  heading_4  heading_5  \\\n",
       "0   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "1   0.689996        0.0        0.0        0.0        0.0        0.0   \n",
       "2   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "3   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "4   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   heading_6  heading_7  heading_8  heading_9  ...  content_1337  \\\n",
       "0        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "3        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "\n",
       "   content_1338  content_1339  content_1340  content_1341  content_1342  \\\n",
       "0           0.0      0.000000           0.0      0.078823      0.101704   \n",
       "1           0.0      0.000000           0.0      0.000000      0.000000   \n",
       "2           0.0      0.000000           0.0      0.000000      0.099908   \n",
       "3           0.0      0.220102           0.0      0.000000      0.000000   \n",
       "4           0.0      0.000000           0.0      0.087057      0.000000   \n",
       "\n",
       "   content_1343  content_1344  content_1345  content_1346  \n",
       "0           0.0           0.0      0.155937           0.0  \n",
       "1           0.0           0.0      0.000000           0.0  \n",
       "2           0.0           0.0      0.000000           0.0  \n",
       "3           0.0           0.0      0.000000           0.0  \n",
       "4           0.0           0.0      0.172226           0.0  \n",
       "\n",
       "[5 rows x 1405 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>heading_0</th>\n      <th>heading_1</th>\n      <th>heading_2</th>\n      <th>heading_3</th>\n      <th>heading_4</th>\n      <th>heading_5</th>\n      <th>heading_6</th>\n      <th>heading_7</th>\n      <th>heading_8</th>\n      <th>heading_9</th>\n      <th>...</th>\n      <th>content_1337</th>\n      <th>content_1338</th>\n      <th>content_1339</th>\n      <th>content_1340</th>\n      <th>content_1341</th>\n      <th>content_1342</th>\n      <th>content_1343</th>\n      <th>content_1344</th>\n      <th>content_1345</th>\n      <th>content_1346</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.078823</td>\n      <td>0.101704</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.155937</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.689996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.099908</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.220102</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.087057</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.172226</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1405 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_vectors_tfidf.to_csv(\"../data/vectorized/vectorized_tfidf.csv\", index=False)\n",
    "df_vectors_tfidf.head()"
   ]
  },
  {
   "source": [
    "## spacy vectors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "nlp = en_core_web_lg.load(disable = ['ner', 'tagger', 'parser'])\n",
    "nlp(\"bruh this is nlp\").vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(document, nlp):\n",
    "    vector_output = []\n",
    "    for word in document.split(\" \"):\n",
    "        if word in nlp.vocab:\n",
    "            nlp_word = nlp(word)\n",
    "            vector_output.append(nlp(nlp_word[-1].lemma_).vector)\n",
    "        else:\n",
    "            nlp.vocab.set_vector(word, np.random.randn(300))\n",
    "            vector_output.append(nlp(word).vector)\n",
    "    \n",
    "    return np.mean(vector_output, axis=0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7900/7900 [00:05<00:00, 1349.96it/s]\n",
      "100%|██████████| 7900/7900 [00:28<00:00, 273.46it/s]\n"
     ]
    }
   ],
   "source": [
    "heading_vectors_spacy = data.loc[:, \"heading\"].progress_apply(\n",
    "    lambda article: vectorize(document=article, nlp=nlp)\n",
    ")\n",
    "content_vectors_spacy = data.loc[:, \"content\"].progress_apply(\n",
    "    lambda article: vectorize(document=article, nlp=nlp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors_spacy = pd.DataFrame(\n",
    "    data=np.concatenate(content_vectors_spacy.values.reshape(-1)).reshape(-1, 300),\n",
    "    columns=[f\"content_{i}\" for i in range(300)]\n",
    ")\n",
    "df_vectors_spacy_h = pd.DataFrame(\n",
    "    data=np.concatenate(heading_vectors_spacy.values.reshape(-1)).reshape(-1, 300),\n",
    "    columns=[f\"heading_{i}\" for i in range(300)]\n",
    ")\n",
    "df_vectors_spacy = pd.concat(objs=[df_vectors_spacy_h, df_vectors_spacy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(7900, 600)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   heading_0  heading_1  heading_2  heading_3  heading_4  heading_5  \\\n",
       "0  -0.546659  -0.261546  -0.348887  -0.238572   0.458753  -0.179026   \n",
       "1  -0.374014   0.079800  -0.307247  -0.388248   0.658381  -0.388981   \n",
       "2   0.182761  -0.229877  -0.521939   0.445496   0.392754  -0.374589   \n",
       "3  -0.148774   0.765963  -0.061879   0.101832   0.199750   0.392823   \n",
       "4  -0.236198  -0.339241  -0.252501  -0.046377  -0.600450   0.195566   \n",
       "\n",
       "   heading_6  heading_7  heading_8  heading_9  ...  content_290  content_291  \\\n",
       "0   0.239807   0.192216  -0.173710   0.316083  ...    -0.114826     0.193850   \n",
       "1   0.700401   0.058361   0.230552  -0.509046  ...    -0.068768    -0.062376   \n",
       "2   0.183456   0.574266   0.218962  -0.057935  ...    -0.082321     0.121098   \n",
       "3  -0.272694  -0.073629   0.138436  -0.154620  ...    -0.152583    -0.247430   \n",
       "4  -0.266664   0.230694   0.595979  -0.169330  ...    -0.071191     0.213485   \n",
       "\n",
       "   content_292  content_293  content_294  content_295  content_296  \\\n",
       "0     0.022486     0.117654     0.031892    -0.145199     0.073625   \n",
       "1     0.025082    -0.042379    -0.101772     0.114503     0.123833   \n",
       "2     0.011565    -0.157940     0.014343    -0.037302     0.032055   \n",
       "3     0.172976     0.074123     0.046913    -0.140058     0.092900   \n",
       "4     0.115562     0.033600     0.121582    -0.068243    -0.059087   \n",
       "\n",
       "   content_297  content_298  content_299  \n",
       "0     0.077310     0.024157     0.009043  \n",
       "1     0.048265     0.000809    -0.040062  \n",
       "2     0.066054    -0.068794     0.051896  \n",
       "3     0.050058    -0.136006    -0.101694  \n",
       "4    -0.006863     0.098188    -0.085795  \n",
       "\n",
       "[5 rows x 600 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>heading_0</th>\n      <th>heading_1</th>\n      <th>heading_2</th>\n      <th>heading_3</th>\n      <th>heading_4</th>\n      <th>heading_5</th>\n      <th>heading_6</th>\n      <th>heading_7</th>\n      <th>heading_8</th>\n      <th>heading_9</th>\n      <th>...</th>\n      <th>content_290</th>\n      <th>content_291</th>\n      <th>content_292</th>\n      <th>content_293</th>\n      <th>content_294</th>\n      <th>content_295</th>\n      <th>content_296</th>\n      <th>content_297</th>\n      <th>content_298</th>\n      <th>content_299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.546659</td>\n      <td>-0.261546</td>\n      <td>-0.348887</td>\n      <td>-0.238572</td>\n      <td>0.458753</td>\n      <td>-0.179026</td>\n      <td>0.239807</td>\n      <td>0.192216</td>\n      <td>-0.173710</td>\n      <td>0.316083</td>\n      <td>...</td>\n      <td>-0.114826</td>\n      <td>0.193850</td>\n      <td>0.022486</td>\n      <td>0.117654</td>\n      <td>0.031892</td>\n      <td>-0.145199</td>\n      <td>0.073625</td>\n      <td>0.077310</td>\n      <td>0.024157</td>\n      <td>0.009043</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.374014</td>\n      <td>0.079800</td>\n      <td>-0.307247</td>\n      <td>-0.388248</td>\n      <td>0.658381</td>\n      <td>-0.388981</td>\n      <td>0.700401</td>\n      <td>0.058361</td>\n      <td>0.230552</td>\n      <td>-0.509046</td>\n      <td>...</td>\n      <td>-0.068768</td>\n      <td>-0.062376</td>\n      <td>0.025082</td>\n      <td>-0.042379</td>\n      <td>-0.101772</td>\n      <td>0.114503</td>\n      <td>0.123833</td>\n      <td>0.048265</td>\n      <td>0.000809</td>\n      <td>-0.040062</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.182761</td>\n      <td>-0.229877</td>\n      <td>-0.521939</td>\n      <td>0.445496</td>\n      <td>0.392754</td>\n      <td>-0.374589</td>\n      <td>0.183456</td>\n      <td>0.574266</td>\n      <td>0.218962</td>\n      <td>-0.057935</td>\n      <td>...</td>\n      <td>-0.082321</td>\n      <td>0.121098</td>\n      <td>0.011565</td>\n      <td>-0.157940</td>\n      <td>0.014343</td>\n      <td>-0.037302</td>\n      <td>0.032055</td>\n      <td>0.066054</td>\n      <td>-0.068794</td>\n      <td>0.051896</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.148774</td>\n      <td>0.765963</td>\n      <td>-0.061879</td>\n      <td>0.101832</td>\n      <td>0.199750</td>\n      <td>0.392823</td>\n      <td>-0.272694</td>\n      <td>-0.073629</td>\n      <td>0.138436</td>\n      <td>-0.154620</td>\n      <td>...</td>\n      <td>-0.152583</td>\n      <td>-0.247430</td>\n      <td>0.172976</td>\n      <td>0.074123</td>\n      <td>0.046913</td>\n      <td>-0.140058</td>\n      <td>0.092900</td>\n      <td>0.050058</td>\n      <td>-0.136006</td>\n      <td>-0.101694</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.236198</td>\n      <td>-0.339241</td>\n      <td>-0.252501</td>\n      <td>-0.046377</td>\n      <td>-0.600450</td>\n      <td>0.195566</td>\n      <td>-0.266664</td>\n      <td>0.230694</td>\n      <td>0.595979</td>\n      <td>-0.169330</td>\n      <td>...</td>\n      <td>-0.071191</td>\n      <td>0.213485</td>\n      <td>0.115562</td>\n      <td>0.033600</td>\n      <td>0.121582</td>\n      <td>-0.068243</td>\n      <td>-0.059087</td>\n      <td>-0.006863</td>\n      <td>0.098188</td>\n      <td>-0.085795</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 600 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_vectors_spacy.to_csv(\"../data/vectorized/vectorized_spacy.csv\", index=False)\n",
    "print(df_vectors_spacy.shape)\n",
    "df_vectors_spacy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.11840403]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "cosine_similarity(df_vectors_spacy.loc[13].values.reshape(1, -1), df_vectors_spacy.loc[34].values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.3291562]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "cosine_similarity(np.array(df_vectors_tfidf.loc[13].values).reshape(1, -1),\n",
    "np.array(df_vectors_tfidf.loc[1].values).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}